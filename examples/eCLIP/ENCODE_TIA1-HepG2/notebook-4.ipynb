{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def index_tfrecord(tfrecord, index_filepath):\n",
    "    with open(tfrecord, 'rb') as tfr, open(index_filepath, 'w') as idx:\n",
    "        while True:\n",
    "            current = tfr.tell()\n",
    "            try:\n",
    "                # byte length\n",
    "                byte_len = tfr.read(8)\n",
    "                if len(byte_len) == 0:\n",
    "                    break\n",
    "\n",
    "                # crc length\n",
    "                byte_len_crc = tfr.read(4)\n",
    "                proto_len = struct.unpack('q', byte_len)[0]\n",
    "\n",
    "                # proto\n",
    "                tfr.read(proto_len)\n",
    "\n",
    "                # crc\n",
    "                tfr.read(4)\n",
    "                print(str(current) + '\\t' + str(tfr.tell() - current), file=idx)\n",
    "            except Exception:\n",
    "                print('Not a valid TFRecord file.')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_tfrecord('test.tfrecord', 'test.tfrecord.idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeaturesDict({\n",
       "    'inputs': FeaturesDict({\n",
       "        'sequence': Tensor(shape=(None, 4), dtype=int8),\n",
       "    }),\n",
       "    'outputs': FeaturesDict({\n",
       "        'SomeTask': FeaturesDict({\n",
       "            'total': Tensor(shape=(None,), dtype=float32),\n",
       "        }),\n",
       "    }),\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bioflow.io import dataset_ops\n",
    "\n",
    "features = dataset_ops.features_from_json_file('test.tfrecord.features.json')\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# with open('test.tfrecord', 'rb') as tfrecord:\n",
    "with tf.io.gfile.GFile('test.tfrecord', 'rb') as tfrecord:\n",
    "    tfrecord.seek(tf.constant(780, dtype=tf.int64)) # 780\n",
    "    record_bytes = tfrecord.read(348)\n",
    "    proto_bytes = record_bytes[(8+4):-4]\n",
    "record_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(tf.constant(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioflow.io.dataset_ops import better_py_function_kwargs\n",
    "\n",
    "class GFileTFRecord:\n",
    "    def __init__(self, filepath, features=None):\n",
    "        self._gfile_tfrecord = tf.io.gfile.GFile(filepath, 'rb')\n",
    "        self.features = features\n",
    "    \n",
    "    def _seek_and_read(self, offset, length):\n",
    "        offset, length = int(offset), int(length)\n",
    "\n",
    "        self._gfile_tfrecord.seek(offset)\n",
    "        return self._gfile_tfrecord.read(length)[(8+4):-4]\n",
    "\n",
    "    def read_proto(self, offset, length):\n",
    "        proto_bytes = tf.py_function(self._seek_and_read, inp=[offset, length], Tout=tf.string)\n",
    "        proto_bytes.set_shape(shape=())\n",
    "        return proto_bytes\n",
    "    \n",
    "    def read_example(self, offset, length):\n",
    "        proto = self.read_proto(offset, length)\n",
    "        return features.deserialize_example(proto)\n",
    "\n",
    "gfile_tfrecord = GFileTFRecord('test.tfrecord', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 16:02:06.457811: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-03 16:02:06.457874: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-03 16:02:06.457921: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-03 16:02:06.457968: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-02-03 16:02:06.458015: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-02-03 16:02:06.458061: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-03 16:02:06.458106: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-03 16:02:06.458154: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-03 16:02:06.458780: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\n\\xc9\\x02\\n\\xbc\\x01\\n\\x16outputs/SomeTask/total\\x12\\xa1\\x01\\n\\x9e\\x01\\n\\x9b\\x01x\\x9cc`h\\xb0g`pp`\\x00\\xd30\\xf6\\x02(f\\x00b\\x03G\\x888\\x88}\\x00I\\x1c\\x8c\\x19\\xd0\\xd8\\xd8\\x00>\\xb9\\x11\\x08\\xc0a\\x89\\x03H810\\xbc\\x03\\xe2E\\xce\\x0c\\x0c\\xe7\\x804\\x03\\x10\\xbf\\x00\\x86\\xff\\x04 6\\x00\\xb2\\x0b\\x80\\xf4\\x0e \\x16q\\x82\\xc4\\x05(l\\x1d\\xa04,\\xfe\\x1a\\xa0\\xfc\\x07 \\xda\\x11\\xc2\\x87\\xc5+X\\x9d\\x03\\xaa\\x1b\\xc0\\xe60 \\xf4\\xe3\\x02\\xc8\\xf1\\xde\\x80\\xc4v@b\\'8\"\\xf1\\x91\\xfc\\xeb\\x00U\\xd7\\x00u\\x17\\xdc\\xad\\xf6\\xa8j\\x1d\\xd0\\xdc\\x02\\xc2\\x0f\\xd0\\xcc\\x82\\xbb\\xd1\\x01\\xd3\\xfd\\xb4\\x01\\x00\\x9b\\x8b1L\\n\\x87\\x01\\n\\x0finputs/sequence\\x12t\\nr\\npx\\x9c\\xadQK\\x16\\x00!\\x08\\x92\\xfb_z\\x16\\xe5 \\x8a\\xbb\\xde\\xeb\\xa3 \\x95\\x11\\x11\\xc8\\x11g\\x85\\xc4\\xc2m\\xf1\\xd5l\\xdcI |\\xbd*qV^(\\xe0rj\\xc8J\\xfd\\xa3\\x9d-\\xf1e\\x1b\\xbf\\xedu:\\xcc\\xcdq\\xb7\\x02\\xff\\xffIjA(\\x8e\\xf66\\x91.>v\\x0f\\xab\\x07j \\x8a\\x8d\\xa2\\xb4\\xe7\\x8c\\x9e\\x1aV\\xab\\x1d\\xdf\\xfc\\x18\\xf5\\xa2m\\xfd\\xb9\\x7f7x\\x06\\x1f?\\x03\\x00\\xca'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto = gfile_tfrecord.read_proto(780, 348)\n",
    "proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': {'sequence': <tf.Tensor: shape=(201, 4), dtype=int8, numpy=\n",
       "  array([[0, 0, 0, 1],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 1, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 1, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 1, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 1, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 1, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 1, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 1, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [0, 0, 0, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [1, 0, 0, 0]], dtype=int8)>},\n",
       " 'outputs': {'SomeTask': {'total': <tf.Tensor: shape=(201,), dtype=float32, numpy=\n",
       "   array([  1.,   3.,   1.,   1.,   3.,   5.,   5.,   2.,  11.,   1.,   2.,\n",
       "            6.,   5.,   2.,   2.,   0.,   2.,   2.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           38., 119., 324., 103.,  32.,  29.,  18.,  44.,  15.,  23.,  37.,\n",
       "            6.,   2.,   3.,   2.,   1.,   1.,   4.,   2.,   7.,   8.,   4.,\n",
       "            1.,   3.,   2.,   4.,   1.,   0.,   0.,   6.,   0.,   1.,   1.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   5.,   2.,   2.,   4.,   2.,\n",
       "            2.,   3.,   2.,   2.,  14.,   3.,   2.,   0.,   0.,   1.,   3.,\n",
       "            3.,   4.,   7.,   1.,   1.,   1.,   2.,   0.,   0.,   3.,   0.,\n",
       "            1.,   1.,   1.,   7.,   0.,   0.,   1.,   1.,   0.,   2.,   0.,\n",
       "            6.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.], dtype=float32)>}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.deserialize_example(proto, decoders=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = gfile_tfrecord.read_example(780, 348)\n",
    "example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = gfile_tfrecord.read_example(tf.constant(780, dtype=tf.int64), tf.constant(348, dtype=tf.int64))\n",
    "example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_length = []\n",
    "with open('test.tfrecord.idx') as f:\n",
    "    for line in f:\n",
    "        offset, length = line.strip().split()\n",
    "        offset_length.append([int(offset), int(length)])\n",
    "print(len(offset_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,    348],\n",
       "       [   348,    432],\n",
       "       [   780,    348],\n",
       "       ...,\n",
       "       [180570,    249],\n",
       "       [180819,    372],\n",
       "       [181191,    283]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_index(filepath):\n",
    "    return np.array(pd.read_csv(filepath, sep='\\t', header=None), dtype=np.int64)\n",
    "\n",
    "index = load_index('test.tfrecord.idx')\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def index_to_dataset(filepath):\n",
    "    index = load_index(filepath)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((index[:, 0], index[:, 1]))\n",
    "    return dataset\n",
    "\n",
    "idx_dataset = index_to_dataset('test.tfrecord.idx')\n",
    "print(idx_dataset)\n",
    "print(next(iter(idx_dataset)))\n",
    "print(idx_dataset.cardinality())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_dataset = idx_dataset.map(gfile_tfrecord.read_proto).shuffle(np.inf)\n",
    "print(proto_dataset)\n",
    "print(next(iter(proto_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_dataset = tf.data.Dataset.from_tensor_slices(offset_length)\n",
    "idx_dataset = idx_dataset.map(lambda x: (tf.cast(x[0], tf.int64), tf.cast(x[1], tf.int64)))\n",
    "idx_dataset = idx_dataset.repeat(1)\n",
    "idx_dataset = idx_dataset.shuffle(1_000_000)\n",
    "print(idx_dataset)\n",
    "print(next(iter(idx_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_dataset = idx_dataset.take(1).map(gfile_tfrecord.read_proto)\n",
    "proto_dataset\n",
    "\n",
    "print(next(iter(proto_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset = idx_dataset.map(gfile_tfrecord.read_example)\n",
    "example_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for example in example_dataset:\n",
    "    x = example\n",
    "    n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.deserialize_example(proto_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(12182, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "from bioflow.io import load_indexed_tfrecord\n",
    "\n",
    "dataset = load_indexed_tfrecord('/home/marc/Downloads/windows.shard-112.tfrecord', shuffle=1000)\n",
    "# print(dataset)\n",
    "# print(next(iter(dataset)).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12182\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for example in dataset:\n",
    "    _ = example\n",
    "    n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.171875"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyBigWig\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.18\n",
      "1.24.1\n"
     ]
    }
   ],
   "source": [
    "print(pyBigWig.__version__)\n",
    "print(np.__version__)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "921f9b6c09b878a5d0bda5ea1d77d940e10ba56e9ae7f606fddb109a1ea3e17e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 ('bioflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
